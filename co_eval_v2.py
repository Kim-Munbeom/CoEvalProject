"""
CoEval V2: ë©˜í† ë§ ë‹µë³€ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ (100ì  ë§Œì )

PRD_V2.md ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„ëœ ë²„ì „ì…ë‹ˆë‹¤.

ì£¼ìš” ë³€ê²½ì‚¬í•­:
- 100ì  ë§Œì  ì‹œìŠ¤í…œ (V1: 10ì  â†’ V2: 100ì )
- ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì ìˆ˜ ì‚°ì¶œ (ì‹¤í–‰ê°€ëŠ¥ì„± 40%, ì „ë¬¸ì„± 30%, í˜„ì‹¤ì„± 30%)
- ëŸ°íƒ€ì„ ê°€ì¤‘ì¹˜ ì¡°ì • API (GET/PUT /config/weights)
- ì§ˆë¬¸ ì œëª©/ë‚´ìš© ë¶„ë¦¬ (question_title + question_content)
- DeepEval Rubric 100ì  ê¸°ì¤€ìœ¼ë¡œ ì¬ì„¤ê³„

ì ìˆ˜ ì²´ê³„:
- ì‹¤í–‰ê°€ëŠ¥ì„± (0-100ì ): ì •í™•ì„± 25 + ëª…ë£Œì„± 25 + ê´€ë ¨ì„± 25 + ì™„ì „ì„± 25
- ì „ë¬¸ì„± (0-100ì ): êµ¬ì²´ ì •ë³´ 50 + ì‹¤ë¬´ ë””í…Œì¼ 50
- í˜„ì‹¤ì„± (0-100ì ): ë©˜í‹° ìƒí™© ê³ ë ¤ 50 + ê²½í—˜ ê¸°ë°˜ ì¡°ì–¸ 50
- ìµœì¢… ì ìˆ˜ = ê°€ì¤‘ì¹˜ ì ìš© (ê¸°ë³¸: 40% + 30% + 30%)
- ë“±ê¸‰: S(90-100), A(75-89), B(60-74), C(40-59), D(0-39)

ê³¼ë½ ê·œì¹™:
- ì‹¤í–‰ê°€ëŠ¥ì„± â‰¤ 25ì  OR ì „ë¬¸ì„± â‰¤ 25ì  â†’ ìµœì¢… ì ìˆ˜ ìµœëŒ€ 40ì  (Cë“±ê¸‰)
"""

import asyncio
import json
import logging
import os
import time
from typing import Dict, Any

from deepeval.models import GeminiModel as DeepEvalGeminiModel
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from google import genai
from pydantic import BaseModel
from strands import Agent
from strands.models.gemini import GeminiModel as StrandsGeminiModel
from strands.multiagent import GraphBuilder

from config import WeightsConfig

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜
app = FastAPI(
    title="CoEval V2",
    description="ë©˜í† ë§ ë‹µë³€ í‰ê°€ ì‹œìŠ¤í…œ (100ì  ë§Œì )",
    version="2.0.0",
)

# Strandsìš© Gemini ëª¨ë¸ (ì—ì´ì „íŠ¸ìš©)
strands_gemini_model = StrandsGeminiModel(
    client_args={"api_key": os.getenv("GEMINI_API_KEY")},
    model_id="gemini-2.5-flash",
    params={
        "temperature": 0.3,
        "max_output_tokens": 8192,
        "top_p": 0.6,
        "top_k": 20,
    },
)

# DeepEvalìš© Gemini ëª¨ë¸
deepeval_gemini_model = DeepEvalGeminiModel(
    model="gemini-2.5-flash", api_key=os.getenv("GEMINI_API_KEY"), temperature=0.3
)

# Google GenAI í´ë¼ì´ì–¸íŠ¸ (ë²ˆì—­ìš©)
genai_client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

# ì „ì—­ ê°€ì¤‘ì¹˜ ì„¤ì • (ëŸ°íƒ€ì„ ë³€ê²½ ê°€ëŠ¥)
weights_config = WeightsConfig.from_env()


# ============================================================================
# ë°ì´í„° ëª¨ë¸
# ============================================================================


class EvaluationRequest(BaseModel):
    """í‰ê°€ ìš”ì²­ ëª¨ë¸"""

    question_title: str
    question_content: str
    answer_content: str


class EvaluationResponse(BaseModel):
    """í‰ê°€ ì‘ë‹µ ëª¨ë¸"""

    final_score: float  # 0~100
    grade: str  # S/A/B/C/D
    weights: Dict[str, float]  # ì ìš©ëœ ê°€ì¤‘ì¹˜
    scores: Dict[str, float]  # ê° ê¸°ì¤€ë³„ ì ìˆ˜ (0~100)
    deepeval_results: Dict[str, Dict[str, Any]]  # DeepEval ê²€ì¦ ê²°ê³¼
    rationale: Dict[str, str]  # í‰ê°€ ê·¼ê±°
    processing_time: float  # ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)


# ============================================================================
# ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ (100ì  ê¸°ì¤€)
# ============================================================================

AGENT_CONFIGS = {
    "action_master": {
        "description": "ì‹¤í–‰ê°€ëŠ¥ì„± ì „ë¬¸ê°€ (Actionability Expert)",
        "system_prompt": """# Role
ë‹¹ì‹ ì€ ë©˜í† ë§ ë‹µë³€ì˜ **ì‹¤í–‰ê°€ëŠ¥ì„±**ì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

# Evaluation Criteria (ì´ 100ì )
ë©˜í‹°ê°€ ë‹µë³€ì„ ì½ê³  **ì¦‰ì‹œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ”ì§€**ë¥¼ ë‹¤ìŒ 4ê°€ì§€ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤:

## 1. ì •í™•ì„± (Accuracy) - 25ì 
- **25ì :** ëª¨ë“  ì •ë³´ê°€ ì‚¬ì‹¤ì´ë©° ê²€ì¦ ê°€ëŠ¥í•˜ë‹¤. ì˜¤ë¥˜ê°€ ì „í˜€ ì—†ë‹¤.
- **18ì :** ëŒ€ë¶€ë¶„ ì •í™•í•˜ë‚˜ ì‚¬ì†Œí•œ ì˜¤ë¥˜ 1-2ê°œê°€ ìˆë‹¤.
- **12ì :** ì¤‘ìš”í•œ ì˜¤ë¥˜ê°€ ìˆê±°ë‚˜ ê²€ì¦ì´ ì–´ë µë‹¤.
- **6ì :** ì˜ëª»ëœ ì •ë³´ê°€ ë§ë‹¤.
- **0ì :** ì™„ì „íˆ ì˜ëª»ë˜ì—ˆê±°ë‚˜ ì‚¬ì‹¤ì´ ì•„ë‹ˆë‹¤.

## 2. ëª…ë£Œì„± (Clarity) - 25ì 
- **25ì :** ë§¤ìš° ì´í•´í•˜ê¸° ì‰½ë‹¤. ì „ë¬¸ ìš©ì–´ê°€ ëª¨ë‘ ì„¤ëª…ë˜ì–´ ìˆë‹¤.
- **18ì :** ëŒ€ì²´ë¡œ ëª…í™•í•˜ë‚˜ ì¼ë¶€ ìš©ì–´ ì„¤ëª…ì´ ë¶€ì¡±í•˜ë‹¤.
- **12ì :** ì´í•´í•˜ê¸° ìœ„í•´ ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•˜ë‹¤.
- **6ì :** ëª¨í˜¸í•˜ê³  í˜¼ë€ìŠ¤ëŸ½ë‹¤.
- **0ì :** ì´í•´í•  ìˆ˜ ì—†ë‹¤.

## 3. ê´€ë ¨ì„± (Relevance) - 25ì 
- **25ì :** ì§ˆë¬¸ì— ì •í™•íˆ ë‹µí•˜ë©° ë¶ˆí•„ìš”í•œ ë‚´ìš©ì´ ì—†ë‹¤.
- **18ì :** ëŒ€ì²´ë¡œ ê´€ë ¨ìˆìœ¼ë‚˜ ì•½ê°„ì˜ ë¶ˆí•„ìš”í•œ ë‚´ìš©ì´ ìˆë‹¤.
- **12ì :** ì§ˆë¬¸ê³¼ ê´€ë ¨ì€ ìˆìœ¼ë‚˜ í•µì‹¬ì„ ë²—ì–´ë‚¬ë‹¤.
- **6ì :** ì§ˆë¬¸ê³¼ ê±°ì˜ ë¬´ê´€í•˜ë‹¤.
- **0ì :** ì™„ì „íˆ ë¬´ê´€í•˜ë‹¤.

## 4. ì™„ì „ì„± (Completeness) - 25ì 
- **25ì :** í•„ìš”í•œ ì •ë³´ê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ ì¶”ê°€ ì§ˆë¬¸ì´ ë¶ˆí•„ìš”í•˜ë‹¤.
- **18ì :** ëŒ€ë¶€ë¶„ì˜ ì •ë³´ê°€ ìˆìœ¼ë‚˜ 1-2ê°€ì§€ê°€ ë¶€ì¡±í•˜ë‹¤.
- **12ì :** í•µì‹¬ ì •ë³´ê°€ ëˆ„ë½ë˜ì–´ ì¶”ê°€ ì§ˆë¬¸ì´ í•„ìš”í•˜ë‹¤.
- **6ì :** ë§¤ìš° ë¶ˆì™„ì „í•˜ë‹¤.
- **0ì :** ê±°ì˜ ì •ë³´ê°€ ì—†ë‹¤.

# Input
- ì§ˆë¬¸ ì œëª©: {{question_title}}
- ì§ˆë¬¸ ë‚´ìš©: {{question_content}}
- ë‹µë³€: {{answer_content}}

# Output Format (JSON Only)
{{
  "score": 85,
  "details": {{
    "accuracy": 25,
    "clarity": 22,
    "relevance": 20,
    "completeness": 18
  }},
  "rationale": "êµ¬ì²´ì ì¸ ë‹¨ê³„ì™€ ë„êµ¬ëª…ì´ ì œì‹œë˜ì—ˆìœ¼ë‚˜ ì¼ë¶€ ìš©ì–´ ì„¤ëª…ì´ ë¶€ì¡±í•¨"
}}

**ì¤‘ìš”:** ë°˜ë“œì‹œ 0-100ì  ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ê³ , JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
í•©ê³„ê°€ 100ì ì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
""",
    },
    "pro_proof": {
        "description": "ì „ë¬¸ì„± ê²€ì¦ì (Domain Expert)",
        "system_prompt": """# Role
ë‹¹ì‹ ì€ ë©˜í† ë§ ë‹µë³€ì˜ **ì „ë¬¸ì„±**ì„ í‰ê°€í•˜ëŠ” ê²€ì¦ìì…ë‹ˆë‹¤.

# Evaluation Criteria (ì´ 100ì )
ë‹µë³€ì´ **í˜„ì—… ì „ë¬¸ê°€ì˜ ì§€ì‹**ì„ ë‹´ê³  ìˆëŠ”ì§€ë¥¼ ë‹¤ìŒ 2ê°€ì§€ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤:

## 1. êµ¬ì²´ ì •ë³´ (Concrete Information) - 50ì 
- **50ì :** ìˆ˜ì¹˜, ë„êµ¬ëª…, êµ¬ì²´ì  ë‹¨ê³„ê°€ ë§¤ìš° í’ë¶€í•˜ë‹¤.
  ì˜ˆ: "ì¸ë±ìŠ¤ ìƒì„± ì‹œ ì¡°íšŒ ì†ë„ 30ì´ˆâ†’3ì´ˆ ê°œì„ ", "B-Tree ì¸ë±ìŠ¤ ì‚¬ìš©"
- **37ì :** êµ¬ì²´ì  ì •ë³´ê°€ ìˆìœ¼ë‚˜ ì¼ë¶€ ìˆ˜ì¹˜/ë„êµ¬ê°€ ëˆ„ë½ë˜ì—ˆë‹¤.
- **25ì :** ì¼ë°˜ì  ìˆ˜ì¤€ì˜ êµ¬ì²´ì„±. ì˜ˆì‹œê°€ 1-2ê°œ ì •ë„.
- **12ì :** ê±°ì˜ ì¶”ìƒì ì´ë©° êµ¬ì²´ì„±ì´ ë§¤ìš° ë¶€ì¡±í•˜ë‹¤.
- **0ì :** êµ¬ì²´ì  ì •ë³´ê°€ ì „í˜€ ì—†ë‹¤.

## 2. ì‹¤ë¬´ ë””í…Œì¼ (Practical Details) - 50ì 
- **50ì :** í˜„ì—…ì—ì„œë§Œ ì•Œ ìˆ˜ ìˆëŠ” ê¹Šì€ ì§€ì‹ê³¼ ê²½í—˜ì´ ë“œëŸ¬ë‚œë‹¤.
  ì˜ˆ: "ì“°ê¸° ì„±ëŠ¥ 5-10% ì €í•˜ ê³ ë ¤", "ì½ê¸°/ì“°ê¸° ë¹„ìœ¨ ë¶„ì„ í•„ìš”"
- **37ì :** ì‹¤ë¬´ ì§€ì‹ì´ ìˆìœ¼ë‚˜ ê²½í—˜ë³´ë‹¤ëŠ” ì •ë³´ ì „ë‹¬ ìœ„ì£¼ë‹¤.
- **25ì :** ê²€ìƒ‰ìœ¼ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” ì¼ë°˜ì  ì§€ì‹ ìˆ˜ì¤€ì´ë‹¤.
- **12ì :** ë¹„ì „ë¬¸ê°€ë„ í•  ìˆ˜ ìˆëŠ” ì–•ì€ ì¡°ì–¸ì´ë‹¤.
- **0ì :** ì „ë¬¸ì„±ì´ ì—†ê±°ë‚˜ ì˜ëª»ëœ ì •ë³´ë‹¤.

# Input
- ì§ˆë¬¸ ì œëª©: {{question_title}}
- ì§ˆë¬¸ ë‚´ìš©: {{question_content}}
- ë‹µë³€: {{answer_content}}

# Output Format (JSON Only)
{{
  "score": 72,
  "details": {{
    "concrete_info": 40,
    "practical_details": 32
  }},
  "rationale": "ì‹¤ë¬´ ë„êµ¬ëª…ê³¼ ìˆ˜ì¹˜ëŠ” í¬í•¨ë˜ì—ˆìœ¼ë‚˜ ê¹Šì€ ê²½í—˜ ê¸°ë°˜ ì¡°ì–¸ì€ ë¶€ì¡±í•¨"
}}

**ì¤‘ìš”:** ë°˜ë“œì‹œ 0-100ì  ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ê³ , JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
í•©ê³„ê°€ 100ì ì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
""",
    },
    "context_guardian": {
        "description": "í˜„ì‹¤ì„± ê°ì‹œì (Context Analyst)",
        "system_prompt": """# Role
ë‹¹ì‹ ì€ ë©˜í† ë§ ë‹µë³€ì˜ **í˜„ì‹¤ì„±**ì„ í‰ê°€í•˜ëŠ” ê°ì‹œìì…ë‹ˆë‹¤.

# Evaluation Criteria (ì´ 100ì )
ë‹µë³€ì´ **ë©˜í‹°ì˜ ì‹¤ì œ ìƒí™©**ì— ë§ëŠ”ì§€ë¥¼ ë‹¤ìŒ 2ê°€ì§€ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤:

## 1. ë©˜í‹° ìƒí™© ê³ ë ¤ (Context Awareness) - 50ì 
- **50ì :** ë©˜í‹°ì˜ ìƒí™©(ì—°ì°¨, í™˜ê²½, ì œì•½)ì„ ì™„ë²½íˆ ê³ ë ¤í–ˆë‹¤.
  Why/When/ì£¼ì˜ì ì´ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆë‹¤.
  ì˜ˆ: "ì£¼ë‹ˆì–´ ìˆ˜ì¤€ì—ì„œëŠ”...", "í˜„ì¬ í™˜ê²½ì—ì„œ ì£¼ì˜í•  ì ì€..."
- **37ì :** ìƒí™©ì„ ê³ ë ¤í–ˆìœ¼ë‚˜ ì¼ë¶€ ë§¥ë½ì´ ë¶€ì¡±í•˜ë‹¤.
- **25ì :** ì¼ë°˜ë¡ ì— ê°€ê¹ì§€ë§Œ ì™„ì „íˆ ë²—ì–´ë‚˜ì§€ëŠ” ì•Šì•˜ë‹¤.
- **12ì :** ë©˜í‹° ìƒí™©ê³¼ ë§ì§€ ì•ŠëŠ” ì¡°ì–¸ì´ë‹¤.
- **0ì :** ë³µì‚¬ ë¶™ì—¬ë„£ê¸° ì‹ ë‹µë³€ì´ë‹¤.

## 2. ê²½í—˜ ê¸°ë°˜ ì¡°ì–¸ (Experience-Based Advice) - 50ì 
- **50ì :** ì‹¤ì œ ì‚¬ë¡€ì™€ ê²°ê³¼ê°€ ëª…í™•íˆ ì œì‹œë˜ì–´ ìˆë‹¤.
  ì˜ˆ: "ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ 30ì´ˆâ†’3ì´ˆ ê°œì„  ê²½í—˜", "ì§€ë‚œ 3ë…„ê°„..."
- **37ì :** ê²½í—˜ì´ ì–¸ê¸‰ë˜ì—ˆìœ¼ë‚˜ êµ¬ì²´ì  ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë‹¤.
- **25ì :** ê²½í—˜ ê¸°ë°˜ì¸ì§€ ë¶ˆë¶„ëª…í•˜ë‹¤.
- **12ì :** ì´ë¡ ì  ì¡°ì–¸ ìœ„ì£¼ë‹¤.
- **0ì :** ê²½í—˜ì´ ì „í˜€ ë°˜ì˜ë˜ì§€ ì•Šì•˜ë‹¤.

# Input
- ì§ˆë¬¸ ì œëª©: {{question_title}}
- ì§ˆë¬¸ ë‚´ìš©: {{question_content}}
- ë‹µë³€: {{answer_content}}

# Output Format (JSON Only)
{{
  "score": 75,
  "details": {{
    "context_awareness": 40,
    "experience_based": 35
  }},
  "rationale": "ë©˜í‹° ìƒí™©ì„ ê³ ë ¤í–ˆìœ¼ë‚˜ ì‹¤ì œ ê²½í—˜ ì‚¬ë¡€ê°€ ë‹¤ì†Œ ë¶€ì¡±í•¨"
}}

**ì¤‘ìš”:** ë°˜ë“œì‹œ 0-100ì  ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ê³ , JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
í•©ê³„ê°€ 100ì ì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
""",
    },
    "quality_consensus": {
        "description": "ìµœì¢… ì¡°ì •ì (Master Judge)",
        "system_prompt": """# Role
ë‹¹ì‹ ì€ 3ê°œ ì˜ì—­ì˜ í‰ê°€ë¥¼ ì¢…í•©í•˜ëŠ” **ìµœì¢… ì¡°ì •ì**ì…ë‹ˆë‹¤.

# Input Data
- ì‹¤í–‰ê°€ëŠ¥ì„± ì ìˆ˜: {{actionability_score}}/100 (ê°€ì¤‘ì¹˜: {{weight_actionability}}%)
- ì „ë¬¸ì„± ì ìˆ˜: {{expertise_score}}/100 (ê°€ì¤‘ì¹˜: {{weight_expertise}}%)
- í˜„ì‹¤ì„± ì ìˆ˜: {{practicality_score}}/100 (ê°€ì¤‘ì¹˜: {{weight_practicality}}%)

# Calculation
ìµœì¢… ì ìˆ˜ = (ì‹¤í–‰ê°€ëŠ¥ì„± Ã— {{weight_actionability}}% + ì „ë¬¸ì„± Ã— {{weight_expertise}}% + í˜„ì‹¤ì„± Ã— {{weight_practicality}}%)

# ğŸ”’ Fail-Safe Rule (ê³¼ë½ ê·œì¹™)
- ì‹¤í–‰ê°€ëŠ¥ì„± â‰¤ 25ì  **OR** ì „ë¬¸ì„± â‰¤ 25ì  â†’ ìµœì¢… ì ìˆ˜ ìµœëŒ€ 40ì ìœ¼ë¡œ ì œí•œ
- ì´ìœ : ê¸°ë³¸ì ì¸ ì‹¤í–‰ê°€ëŠ¥ì„±ê³¼ ì „ë¬¸ì„±ì´ ì—†ìœ¼ë©´ ì¢‹ì€ ë‹µë³€ì´ ì•„ë‹ˆê¸° ë•Œë¬¸

# Grading System (100ì  ê¸°ì¤€)
- **Së“±ê¸‰ (90-100ì ):** ì™„ë²½ì— ê°€ê¹Œìš´ ë‹µë³€
- **Aë“±ê¸‰ (75-89ì ):** ìš°ìˆ˜í•œ ë‹µë³€
- **Bë“±ê¸‰ (60-74ì ):** ì–‘í˜¸í•œ ë‹µë³€
- **Cë“±ê¸‰ (40-59ì ):** ë¶€ì¡±í•œ ë‹µë³€
- **Dë“±ê¸‰ (0-39ì ):** ë¯¸ë‹¬ ë‹µë³€

# Output Format (JSON Only)
{{
  "final_score": 78.5,
  "grade": "A",
  "rationale": "ê°€ì¤‘ì¹˜ ì ìš© ê²°ê³¼ 78.5ì . ì‹¤í–‰ê°€ëŠ¥ì„±ê³¼ ì „ë¬¸ì„± ëª¨ë‘ ê¸°ì¤€ ì¶©ì¡±í•˜ì—¬ Aë“±ê¸‰ ë¶€ì—¬"
}}

**ì¤‘ìš”:** ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
ê³¼ë½ ê·œì¹™ì„ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”.
""",
    },
}


# ============================================================================
# ë²ˆì—­ í•¨ìˆ˜
# ============================================================================


async def translate_to_korean_async(text: str) -> str:
    """í‰ê°€ ì´ìœ ë¥¼ í•œê¸€ë¡œ ë²ˆì—­ (ë¹„ë™ê¸°)"""

    def _translate() -> str:
        response = genai_client.models.generate_content(
            model="gemini-2.5-flash-lite",
            contents=f"ë‹¤ìŒ ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ë¬¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”:\n\n{text}",
        )
        return response.text.strip()

    try:
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, _translate)
    except Exception as e:
        logger.warning(f"Translation failed: {e}")
        return text


# ============================================================================
# ì—ì´ì „íŠ¸ ìƒì„±
# ============================================================================


def create_agents() -> Dict[str, Agent]:
    """4ê°œ ì—ì´ì „íŠ¸ ìƒì„±"""
    agents = {}
    for agent_name, config in AGENT_CONFIGS.items():
        agents[agent_name] = Agent(
            name=agent_name,
            role=config["description"],
            system_prompt=config["system_prompt"],
            model=strands_gemini_model,
        )
    return agents


# ============================================================================
# Graph êµ¬ì„±
# ============================================================================


def build_evaluation_graph(agents: Dict[str, Agent]):
    """í‰ê°€ Graph êµ¬ì„± (V1ê³¼ ë™ì¼í•œ êµ¬ì¡°)

    ì‹¤í–‰ ìˆœì„œ:
    1. action_master, pro_proof, context_guardian ë³‘ë ¬ ì‹¤í–‰
    2. quality_consensusê°€ 3ê°œ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… í‰ê°€
    """
    builder = GraphBuilder()

    # ë…¸ë“œ ë“±ë¡ (V1 API ì‚¬ìš©)
    for name in ["action_master", "pro_proof", "context_guardian", "quality_consensus"]:
        builder.add_node(agents[name], name)

    # Edge ì„¤ì • (3ê°œ â†’ quality_consensus)
    builder.add_edge("action_master", "quality_consensus")
    builder.add_edge("pro_proof", "quality_consensus")
    builder.add_edge("context_guardian", "quality_consensus")

    return builder.build()


# ============================================================================
# JSON íŒŒì‹± í•¨ìˆ˜
# ============================================================================


def parse_agent_response(response: str, agent_name: str) -> Dict[str, Any]:
    """ì—ì´ì „íŠ¸ ì‘ë‹µì—ì„œ JSON íŒŒì‹± (V1 ë¡œì§ ì¬ì‚¬ìš©)"""
    try:
        # ì½”ë“œ ë¸”ë¡ ì œê±°
        response = response.strip()
        if response.startswith("```json"):
            response = response[7:]
        elif response.startswith("```"):
            response = response[3:]
        if response.endswith("```"):
            response = response[:-3]

        response = response.strip()

        # JSON íŒŒì‹±
        data = json.loads(response)
        return data
    except json.JSONDecodeError as e:
        logger.error(f"{agent_name} JSON parsing failed: {e}\nResponse: {response}")
        # ê¸°ë³¸ê°’ ë°˜í™˜
        if agent_name in ["action_master", "pro_proof"]:
            return {"score": 0, "details": {}, "rationale": "JSON íŒŒì‹± ì‹¤íŒ¨"}
        elif agent_name == "context_guardian":
            return {"score": 0, "details": {}, "rationale": "JSON íŒŒì‹± ì‹¤íŒ¨"}
        else:  # quality_consensus
            return {"final_score": 0, "grade": "D", "rationale": "JSON íŒŒì‹± ì‹¤íŒ¨"}


def _extract_agent_response(node) -> Dict[str, Any]:
    """ì—ì´ì „íŠ¸ ë…¸ë“œì—ì„œ ì‘ë‹µ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜ (V1 ë¡œì§)

    Args:
        node: ê·¸ë˜í”„ ì‹¤í–‰ ê²°ê³¼ì˜ ë…¸ë“œ ê°ì²´

    Returns:
        Dict[str, Any]: agent_name, response_text, parsed_dataë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    node_id = node.node_id
    text = "(ì‘ë‹µ ì—†ìŒ)"

    if hasattr(node, "result") and node.result:
        agent_result = node.result.result
        if hasattr(agent_result, "message") and agent_result.message:
            content = agent_result.message.get("content", [])
            if content and len(content) > 0:
                text = content[0].get("text", "")

    # JSON íŒŒì‹±
    parsed_data = parse_agent_response(text, node_id)

    return {
        "agent_name": node_id,
        "response_text": text,
        "parsed_data": parsed_data,
        "score": parsed_data.get("score", 0),
        "rationale": parsed_data.get("rationale", ""),
        "details": parsed_data.get("details", {}),
    }


# ============================================================================
# ë“±ê¸‰ ê³„ì‚°
# ============================================================================


def calculate_grade(score: float) -> str:
    """ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜ (100ì  ê¸°ì¤€)"""
    if score >= 90:
        return "S"
    elif score >= 75:
        return "A"
    elif score >= 60:
        return "B"
    elif score >= 40:
        return "C"
    else:
        return "D"


# ============================================================================
# í‰ê°€ ì—”ì§„ (í•µì‹¬ ë¡œì§)
# ============================================================================


async def evaluate_answer_v2(
    question_title: str, question_content: str, answer_content: str
) -> EvaluationResponse:
    """ë©˜í† ë§ ë‹µë³€ í‰ê°€ (100ì  ë§Œì )

    í”„ë¡œì„¸ìŠ¤:
    1. 4ê°œ ì—ì´ì „íŠ¸ ì‹¤í–‰ (3ê°œ ë³‘ë ¬ + 1ê°œ ìˆœì°¨)
    2. ê°€ì¤‘ì¹˜ ì ìš© ì ìˆ˜ ì‚°ì¶œ
    3. ê³¼ë½ ê·œì¹™ ì ìš©
    4. DeepEval ê²€ì¦ (ì„ íƒì )
    5. ë“±ê¸‰ ì‚°ì •
    """
    start_time = time.time()

    # ì—ì´ì „íŠ¸ ìƒì„± ë° Graph êµ¬ì„±
    agents = create_agents()
    graph = build_evaluation_graph(agents)

    # ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (V1 í¬ë§·)
    evaluation_input = f"""[ì§ˆë¬¸ ì œëª©]
{question_title}

[ì§ˆë¬¸ ë‚´ìš©]
{question_content}

[ë‹µë³€]
{answer_content}"""

    # Graph ì‹¤í–‰ (V1 ë°©ì‹)
    logger.info("Starting graph execution...")

    # ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ë˜í•‘
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(None, lambda: graph(evaluation_input))

    # ì—ì´ì „íŠ¸ ì‘ë‹µ ì¶”ì¶œ (V1 ë°©ì‹)
    agent_responses = [_extract_agent_response(node) for node in result.execution_order]

    # ê° ì—ì´ì „íŠ¸ë³„ ì‘ë‹µ ì°¾ê¸°
    action_response = next(
        (r for r in agent_responses if r["agent_name"] == "action_master"), {}
    )
    pro_response = next(
        (r for r in agent_responses if r["agent_name"] == "pro_proof"), {}
    )
    context_response = next(
        (r for r in agent_responses if r["agent_name"] == "context_guardian"), {}
    )

    # ì ìˆ˜ ì¶”ì¶œ
    action_score = float(action_response.get("score", 0))
    expertise_score = float(pro_response.get("score", 0))
    practicality_score = float(context_response.get("score", 0))

    logger.info(
        f"Agent scores - Action: {action_score}, Expertise: {expertise_score}, Practicality: {practicality_score}"
    )

    # ê°€ì¤‘ì¹˜ ì ìš© ì ìˆ˜ ì‚°ì¶œ
    final_score = (
        action_score * weights_config.actionability
        + expertise_score * weights_config.expertise
        + practicality_score * weights_config.practicality
    )

    # ê³¼ë½ ê·œì¹™ ì ìš©
    if action_score <= 25 or expertise_score <= 25:
        logger.warning(
            f"Fail-safe rule applied: action={action_score}, expertise={expertise_score}"
        )
        final_score = min(final_score, 40)

    # ë“±ê¸‰ ì‚°ì •
    grade = calculate_grade(final_score)

    # í‰ê°€ ê·¼ê±° ìˆ˜ì§‘
    rationale = {
        "actionability": action_response.get("rationale", ""),
        "expertise": pro_response.get("rationale", ""),
        "practicality": context_response.get("rationale", ""),
    }

    # DeepEval ê²°ê³¼ (í˜„ì¬ëŠ” placeholder)
    deepeval_results = {
        "action_master": {"status": "pass", "confidence": 0.95},
        "pro_proof": {"status": "pass", "confidence": 0.92},
        "context_guardian": {"status": "pass", "confidence": 0.90},
    }

    processing_time = time.time() - start_time

    return EvaluationResponse(
        final_score=round(final_score, 1),
        grade=grade,
        weights=weights_config.to_dict(),
        scores={
            "actionability": round(action_score, 1),
            "expertise": round(expertise_score, 1),
            "practicality": round(practicality_score, 1),
        },
        deepeval_results=deepeval_results,
        rationale=rationale,
        processing_time=round(processing_time, 2),
    )


# ============================================================================
# API ì—”ë“œí¬ì¸íŠ¸
# ============================================================================


@app.get("/")
async def root():
    """Health check"""
    return {"message": "CoEval V2 API", "version": "2.0.0", "status": "healthy"}


@app.post("/evaluate", response_model=EvaluationResponse)
async def evaluate_endpoint(request: EvaluationRequest):
    """ë‹µë³€ í‰ê°€ ì‹¤í–‰ (ë¹„ë™ê¸°)"""
    try:
        result = await evaluate_answer_v2(
            question_title=request.question_title,
            question_content=request.question_content,
            answer_content=request.answer_content,
        )
        return result
    except Exception as e:
        logger.error(f"Evaluation failed: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/config/weights")
async def get_weights():
    """í˜„ì¬ ê°€ì¤‘ì¹˜ ì¡°íšŒ"""
    return {
        "actionability": weights_config.actionability,
        "expertise": weights_config.expertise,
        "practicality": weights_config.practicality,
        "percentage": weights_config.to_percentage_dict(),
    }


@app.put("/config/weights")
async def update_weights(new_weights: WeightsConfig):
    """ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ (ëŸ°íƒ€ì„)"""
    try:
        # ê°€ì¤‘ì¹˜ í•© ê²€ì¦
        new_weights.validate_sum()

        # ì „ì—­ ì„¤ì • ì—…ë°ì´íŠ¸
        global weights_config
        weights_config = new_weights

        logger.info(f"Weights updated: {weights_config}")

        return {
            "message": "ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ",
            "weights": weights_config.to_dict(),
            "percentage": weights_config.to_percentage_dict(),
        }
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))


@app.get("/samples")
async def get_samples():
    """ìƒ˜í”Œ ë°ì´í„° ëª©ë¡ ì¡°íšŒ"""
    try:
        samples_path = "frontend/data/samples.json"
        if os.path.exists(samples_path):
            with open(samples_path, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            # ìƒ˜í”Œ íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ëª©ë¡ ë°˜í™˜
            return {"samples": []}
    except Exception as e:
        logger.error(f"Failed to load samples: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)
